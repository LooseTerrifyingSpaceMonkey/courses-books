{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Regression\n",
    "Regressions is predicting a real number. This is about what this number should be.\n",
    "\n",
    "For example, house prices.\n",
    "\n",
    "Fitting to Mean Squared Error\n",
    "\n",
    "Use R Squared for scoring\n",
    "- 1 is perfect\n",
    "- 0 is awful"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from future.utils import iteritems\n",
    "from builtins import range, input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the data from https://archive.ics.edu/ml/datasets/Airfoil+Self-Noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/airfoil_self_noise.dat', sep='\\t', header=None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "      0    1       2     3         4        5\n0   800  0.0  0.3048  71.3  0.002663  126.201\n1  1000  0.0  0.3048  71.3  0.002663  125.201\n2  1250  0.0  0.3048  71.3  0.002663  125.951\n3  1600  0.0  0.3048  71.3  0.002663  127.591\n4  2000  0.0  0.3048  71.3  0.002663  127.461",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>800</td>\n      <td>0.0</td>\n      <td>0.3048</td>\n      <td>71.3</td>\n      <td>0.002663</td>\n      <td>126.201</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000</td>\n      <td>0.0</td>\n      <td>0.3048</td>\n      <td>71.3</td>\n      <td>0.002663</td>\n      <td>125.201</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1250</td>\n      <td>0.0</td>\n      <td>0.3048</td>\n      <td>71.3</td>\n      <td>0.002663</td>\n      <td>125.951</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1600</td>\n      <td>0.0</td>\n      <td>0.3048</td>\n      <td>71.3</td>\n      <td>0.002663</td>\n      <td>127.591</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2000</td>\n      <td>0.0</td>\n      <td>0.3048</td>\n      <td>71.3</td>\n      <td>0.002663</td>\n      <td>127.461</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1503 entries, 0 to 1502\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       1503 non-null   int64  \n",
      " 1   1       1503 non-null   float64\n",
      " 2   2       1503 non-null   float64\n",
      " 3   3       1503 non-null   float64\n",
      " 4   4       1503 non-null   float64\n",
      " 5   5       1503 non-null   float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 70.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "data = df[[0, 1, 2, 3, 4]].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "y = df[[5]].values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(data, y, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\.conda\\envs\\workspace\\lib\\site-packages\\sklearn\\linear_model\\_base.py:148: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "LinearRegression(n_jobs=1, normalize=False)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(n_jobs=1, normalize=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(n_jobs=1, normalize=False)</pre></div></div></div></div></div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)\n",
    "model.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5128516384386685"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5155501124332972"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[121.36971726],\n       [124.96474141],\n       [121.11096476],\n       [129.94819804],\n       [132.08629823],\n       [126.06764465],\n       [123.40333598],\n       [122.98856859],\n       [130.13617027],\n       [132.46487736],\n       [129.16183988],\n       [128.18428495],\n       [121.78079437],\n       [132.08887526],\n       [127.1193735 ],\n       [127.71376231],\n       [127.87256046],\n       [125.07102193],\n       [120.08894009],\n       [127.24154257],\n       [122.04870746],\n       [126.15762814],\n       [128.64473077],\n       [126.81953355],\n       [123.61303035],\n       [122.72388227],\n       [126.78806202],\n       [134.03326792],\n       [127.7652905 ],\n       [127.31658688],\n       [123.81713096],\n       [126.16681298],\n       [130.74059665],\n       [124.22080721],\n       [124.26124589],\n       [121.65537531],\n       [119.12523272],\n       [126.41898356],\n       [116.74271806],\n       [120.57040543],\n       [128.25368581],\n       [123.37337607],\n       [130.70197122],\n       [131.66367697],\n       [120.4019666 ],\n       [123.67321602],\n       [127.72338246],\n       [111.6759773 ],\n       [121.9178588 ],\n       [126.83475866],\n       [125.57847648],\n       [127.4841595 ],\n       [124.71582684],\n       [127.61637528],\n       [120.68137061],\n       [122.78192026],\n       [125.03696085],\n       [121.17891847],\n       [120.40550343],\n       [121.47411907],\n       [117.80357377],\n       [122.02169866],\n       [123.78940828],\n       [126.75013154],\n       [127.87963553],\n       [125.73718324],\n       [121.48428578],\n       [125.75435761],\n       [132.23923635],\n       [131.66736123],\n       [126.54289184],\n       [124.67401737],\n       [127.50688939],\n       [134.23156756],\n       [125.8103089 ],\n       [122.54886651],\n       [122.29883209],\n       [122.3619945 ],\n       [122.10870907],\n       [123.97613907],\n       [121.19399046],\n       [129.53778433],\n       [126.48671176],\n       [125.04131502],\n       [126.57562697],\n       [125.1338862 ],\n       [125.9883944 ],\n       [128.67353285],\n       [114.54480082],\n       [129.97404209],\n       [126.84858879],\n       [127.86099995],\n       [133.60499347],\n       [120.82103506],\n       [127.3854689 ],\n       [131.41745193],\n       [120.57543078],\n       [129.13278371],\n       [129.40737598],\n       [108.81098786],\n       [129.76211009],\n       [120.45265661],\n       [128.55308649],\n       [128.11253714],\n       [126.67336423],\n       [127.00259345],\n       [129.9346994 ],\n       [123.36451304],\n       [114.07356832],\n       [130.60803331],\n       [119.65999612],\n       [131.84192418],\n       [120.91457025],\n       [125.56940009],\n       [131.10929258],\n       [112.82541079],\n       [125.54979254],\n       [127.12585245],\n       [126.98369469],\n       [131.00386834],\n       [123.68289068],\n       [125.69044446],\n       [127.31612593],\n       [123.02445928],\n       [124.76964145],\n       [130.99477794],\n       [119.81851652],\n       [126.17602566],\n       [124.67921841],\n       [124.40268019],\n       [116.168347  ],\n       [132.05128436],\n       [121.9328286 ],\n       [119.30121743],\n       [121.57366014],\n       [126.61004071],\n       [119.9393097 ],\n       [120.71541125],\n       [131.65033105],\n       [122.24750741],\n       [115.56613011],\n       [125.03242861],\n       [135.72211013],\n       [120.41154406],\n       [130.8707445 ],\n       [117.64066451],\n       [129.42542175],\n       [125.66597723],\n       [128.24347959],\n       [127.30734573],\n       [120.77982131],\n       [113.86047725],\n       [128.5979232 ],\n       [111.12903488],\n       [127.46625828],\n       [125.1947333 ],\n       [116.92192609],\n       [128.17227358],\n       [124.98094808],\n       [129.6321488 ],\n       [129.31211831],\n       [122.63000998],\n       [124.02488028],\n       [123.220401  ],\n       [125.1306967 ],\n       [127.5648387 ],\n       [127.62916754],\n       [133.22867829],\n       [117.696482  ],\n       [125.21949616],\n       [122.18345823],\n       [129.7472574 ],\n       [119.98329224],\n       [118.0861047 ],\n       [121.5606036 ],\n       [133.77278199],\n       [128.86952345],\n       [129.60880089],\n       [129.03293893],\n       [122.59561777],\n       [112.23815971],\n       [129.92093246],\n       [123.30185563],\n       [129.59809764],\n       [121.46714255],\n       [116.76820167],\n       [121.10830839],\n       [124.89417892],\n       [129.37696848],\n       [128.31451963],\n       [128.51717941],\n       [127.52958094],\n       [125.9411944 ],\n       [124.98730441],\n       [126.12090109],\n       [126.41924462],\n       [131.20846534],\n       [119.56649925],\n       [126.0037315 ],\n       [123.42666545],\n       [126.25436114],\n       [115.92385151],\n       [126.15628893],\n       [129.96220191],\n       [133.14285786],\n       [126.3674846 ],\n       [124.54946997],\n       [131.54789444],\n       [112.08406715],\n       [130.6905813 ],\n       [125.09005623],\n       [125.81027041],\n       [123.83151459],\n       [125.32733811],\n       [128.78080189],\n       [128.89014122],\n       [119.43754169],\n       [131.63254645],\n       [124.17855435],\n       [125.04853327],\n       [122.97118089],\n       [125.95595352],\n       [117.61318685],\n       [129.05085579],\n       [117.42149517],\n       [129.23882801],\n       [117.40575796],\n       [120.66813214],\n       [123.28611766],\n       [122.03934619],\n       [122.16772102],\n       [126.87067213],\n       [132.26596325],\n       [131.72527121],\n       [119.489995  ],\n       [122.81142409],\n       [120.12154167],\n       [131.16888163],\n       [128.74473886],\n       [126.54485488],\n       [119.03485058],\n       [122.10925254],\n       [126.45881421],\n       [131.05750952],\n       [128.56927411],\n       [122.94329702],\n       [116.86371264],\n       [133.25554206],\n       [122.30820013],\n       [129.73173426],\n       [122.03003136],\n       [120.96588328],\n       [125.58802348],\n       [123.98011174],\n       [115.74019952],\n       [120.53106485],\n       [129.39637682],\n       [125.11841548],\n       [114.41562974],\n       [132.28881716],\n       [134.79482685],\n       [129.14751679],\n       [128.19567487],\n       [122.3620658 ],\n       [120.48227224],\n       [121.35317471],\n       [122.25916641],\n       [133.0926328 ],\n       [128.9037659 ],\n       [123.82606554],\n       [120.5787228 ],\n       [129.38661165],\n       [116.059072  ],\n       [128.0412102 ],\n       [122.36411293],\n       [123.42928888],\n       [128.00062335],\n       [133.97227607],\n       [125.52075301],\n       [132.06002805],\n       [125.45629567],\n       [123.19078537],\n       [124.71596723],\n       [120.9067627 ],\n       [120.96652515],\n       [121.3506344 ],\n       [130.49678592],\n       [124.80512844],\n       [128.10173697],\n       [104.66545605],\n       [123.61521397],\n       [130.05199584],\n       [124.22174812],\n       [121.09389827],\n       [126.46739633],\n       [118.78498836],\n       [123.53380917],\n       [129.75966691],\n       [128.27719182],\n       [131.74486784],\n       [124.42858877],\n       [124.94207441],\n       [126.55231108],\n       [112.79683444],\n       [134.49333682],\n       [125.55860565],\n       [125.66512325],\n       [126.12151032],\n       [124.76992811],\n       [131.77557153],\n       [118.96354638],\n       [120.29692626],\n       [122.62783802],\n       [132.91682515],\n       [117.19693779],\n       [124.42195918],\n       [125.90927183],\n       [120.2367332 ],\n       [130.58863719],\n       [121.64460452],\n       [123.06626606],\n       [129.19630914],\n       [129.56705857],\n       [129.90863525],\n       [116.45725003],\n       [126.63382444],\n       [123.7844388 ],\n       [127.58433638],\n       [125.46785614],\n       [130.60218528],\n       [123.07218014],\n       [118.56536835],\n       [127.8588401 ],\n       [130.90342781],\n       [131.3758198 ],\n       [132.70760605],\n       [130.16358342],\n       [132.30545019],\n       [118.78245143],\n       [122.41059523],\n       [118.96438303],\n       [122.60804007],\n       [118.47226915],\n       [129.12845671],\n       [132.24920749],\n       [109.67804875],\n       [126.73115318],\n       [118.80134994],\n       [117.76932756],\n       [119.13076133],\n       [126.05071084],\n       [125.05141452],\n       [131.49611138],\n       [125.36458411],\n       [133.59271072],\n       [123.46267866],\n       [131.16610196],\n       [111.96954613],\n       [130.82484285],\n       [124.01883883],\n       [120.36090813],\n       [116.64605891],\n       [118.24181941],\n       [118.31021707],\n       [132.16493624],\n       [123.93352032],\n       [124.1062862 ],\n       [124.94960922],\n       [119.63713876],\n       [128.63472275],\n       [124.38104764],\n       [133.09145145],\n       [127.08864239],\n       [119.32557463],\n       [123.8608063 ],\n       [132.46849826],\n       [121.80890555],\n       [112.85208444],\n       [117.53686903],\n       [116.20386434],\n       [123.30946293],\n       [120.47898623],\n       [117.89920709],\n       [124.03800202],\n       [116.60619438],\n       [120.53087296],\n       [131.02368262],\n       [128.91121025],\n       [125.46060721],\n       [121.6778536 ],\n       [127.65806207],\n       [114.26190532],\n       [124.85254834],\n       [134.94515826],\n       [128.47461305],\n       [131.37913715],\n       [123.99298201],\n       [125.15176572],\n       [118.02457662],\n       [129.347468  ],\n       [123.08501915],\n       [123.29555438],\n       [125.42413676],\n       [118.83617325],\n       [118.68663086],\n       [131.86118149],\n       [122.74492633],\n       [130.79873632],\n       [130.79691021],\n       [123.24558509],\n       [116.17986518],\n       [133.37872304],\n       [125.24613019],\n       [128.15627415],\n       [115.91910913],\n       [122.84328513],\n       [124.45358053],\n       [122.85059618],\n       [119.19486634],\n       [135.30788313],\n       [132.57894118],\n       [123.79758106],\n       [122.12324261],\n       [121.1809397 ],\n       [130.06400721],\n       [123.08426778],\n       [127.52579009],\n       [127.96390477],\n       [120.52764619],\n       [128.93893618],\n       [126.5955491 ],\n       [126.02201228],\n       [123.38495844],\n       [120.45090543],\n       [126.62497757],\n       [123.54441449],\n       [135.73534537],\n       [125.9803817 ],\n       [121.04727223],\n       [121.64389875],\n       [124.20154608],\n       [128.23306499],\n       [129.22005174],\n       [122.75315284],\n       [131.12418898],\n       [131.87326304],\n       [122.12231643],\n       [118.24399137],\n       [125.64793145],\n       [126.63030559],\n       [128.92836483],\n       [132.59013453],\n       [119.60295619],\n       [128.4874725 ],\n       [124.19950475],\n       [124.17098858],\n       [137.43823503],\n       [130.64050006],\n       [134.53452719],\n       [122.1434351 ],\n       [130.17843262],\n       [125.11433642],\n       [125.85586134],\n       [125.7037913 ],\n       [123.3785291 ],\n       [127.86318888],\n       [127.60821047],\n       [129.82536525],\n       [124.88230691],\n       [128.74085664],\n       [108.06091931],\n       [125.78100279],\n       [126.39864539],\n       [115.70266095],\n       [118.50562114],\n       [118.83553138],\n       [126.92605115],\n       [121.48267845],\n       [121.61238487],\n       [119.24100181],\n       [126.27513983],\n       [129.49426738],\n       [132.64958574],\n       [121.10884633],\n       [125.25739071],\n       [125.60469831],\n       [127.29492343],\n       [122.49142725],\n       [130.92241371],\n       [131.63908005],\n       [128.26279174],\n       [116.09632493],\n       [120.4410383 ],\n       [128.29871036],\n       [123.08914427],\n       [124.64014794]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\AppData\\Local\\Temp\\ipykernel_27312\\1492037919.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model2.fit(X_train, Y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": "RandomForestRegressor()",
      "text/html": "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RandomForestRegressor()\n",
    "model2.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9896256647109152"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9202603442170978"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.score(X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
